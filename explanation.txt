Web scrapping: coletar informaçao da Web

 -  Requests: libraria que possibilita enviar HTTP requests para websites ou APIs. Python basicamente vai "falar" com a web, como o browser faz. (requests.get) podemos passar os requests.get para response.json()
    Também permite enviar dados para um servidor (requests.post)
    Alternativa a requests: urllib (mais complexo)

 -  BeautifulSoup: libraria que traduz a informação que conseguimos com o request
    Com o requests obtemos uma pagina html, com o BeautifulSoup traduzimos essa pagina e vamos buscar coisas que queremos (BeautifulSoup(url. 'html.parser'))

Uvicorn:
   -  High-performance web server 

   if __name__ == "__main__":
    uvicorn.run(app)

Saber os requirements do projeto:
   pip freeze > requirements.txt


Venv - Virtual Environment
Cria um ambiente isolado para um projeto com:
-os seus pacotes Python
-o seu proprio pip
-sem intereferência com os outros projetos ou sistemas

Container:
-Mini máquina que corre a nossa app, incluindo:
   -código
   -dependencias
   -ambiente

Images:
-Define tudo o que a nossa app precisa: OS, versão Python, librarias, código, etc: daqui, o Docker consegue criar quantos containers quiseres

Dockerfile:
-script que diz ao docker como construir imagem
Exemplo:
#########################################################
# Use Python 3.11 as base image
FROM python:3.11

# Set working directory inside container
WORKDIR /app

# Copy dependencies file
COPY requirements.txt .

# Install dependencies
RUN pip install -r requirements.txt

# Copy the rest of the app
COPY . .

# Command to run your app
CMD ["python", "app.py"]
#########################################################